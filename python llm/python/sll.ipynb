{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260978fc-d107-4afa-953e-e2bdc90f3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from sklearn.metrics import r2_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27eadfab-72b6-42f1-87f7-c3baf2979f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "CPU times: user 3.71 ms, sys: 20 ms, total: 23.7 ms\n",
      "Wall time: 23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c8d8ac5-c7ad-4799-83a4-554425a2351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139773\n"
     ]
    }
   ],
   "source": [
    "input_file = \"shakespear.txt\"\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "print(len(text))\n",
    "vocab_size = len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9267ca66-f74a-423f-a924-b0b820f9de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, nmbr_of_samples, lenght_of_samples, for_training, len_for_test):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    text2 = []\n",
    "    sorted_set = sorted(set(text))\n",
    "    dictionary_set = dict()\n",
    "    for i in range(len(sorted_set)):\n",
    "        dictionary_set[sorted_set[i]] = i\n",
    "    #print(sorted_set)\n",
    "    #print(dictionary_set)\n",
    "    for i in range(len(text)):\n",
    "        break\n",
    "    x = np.zeros((nmbr_of_samples, lenght_of_samples), dtype=float)\n",
    "    y = np.zeros((nmbr_of_samples, 1))\n",
    "    if (for_training == 1):\n",
    "        minimum = 0\n",
    "        maximum = len(text) - len_for_test - 1 - lenght_of_samples\n",
    "    else:\n",
    "        minimum = len(text) - len_for_test\n",
    "        maximum = len(text) - 1 - lenght_of_samples\n",
    "    #print(\"set: \", sorted(set(text)))\n",
    "    for i in range(nmbr_of_samples):\n",
    "        r = random.randint(minimum, maximum)\n",
    "        string = text[r:r+lenght_of_samples+1]\n",
    "        string2 = []\n",
    "        #string = [ord(char) for char in string]\n",
    "        for ii in range(len(string)):\n",
    "            string2.append(dictionary_set[string[ii]])\n",
    "        x[i, :] = string2[0:lenght_of_samples]\n",
    "        y[i, :] = string2[lenght_of_samples]\n",
    "        string2 = []\n",
    "    return x, y, dictionary_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b5371e8-bf83-4c51-ba72-39f799ad8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 512)\n",
    "        self.linear2 = nn.Linear(512, 128)\n",
    "        self.linear3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.sigm(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, input_size, learning_rate, num_epochs):\n",
    "        self.model = SimpleModel(input_size)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    def train(self, inputs, targets):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Forward pass\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Print progress\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{self.num_epochs}], Loss: {loss.item():.4f}\")\n",
    "            print(epoch+1, end=\" \")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        with torch.no_grad():\n",
    "            return self.model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c5226e2-c3c7-4b1b-b9ee-cd8d0f56da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 CPU times: user 13.1 s, sys: 78.5 ms, total: 13.2 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_size = 20\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "def get_dataset():\n",
    "    global input_file\n",
    "    x, y, dictionary_set = get_data(input_file, 10000, input_size, True, 10000)\n",
    "    x = torch.tensor(x)/vocab_size\n",
    "    y = torch.tensor(y)/vocab_size\n",
    "    x,y=x.type(torch.FloatTensor),y.type(torch.FloatTensor)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    return x, y, dictionary_set\n",
    "\n",
    "trainer = Trainer(input_size, learning_rate, num_epochs)\n",
    "\n",
    "num_cores = torch.get_num_threads()  # Get the number of available CPU cores\n",
    "for i in range(1):\n",
    "    x, y, dictionary_set = get_dataset()\n",
    "    trainer.train(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "720f530f-ad5a-4863-93bc-bd34c70dd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\n",
      "['b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b']\n",
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, ':': 9, ';': 10, '?': 11, 'A': 12, 'B': 13, 'C': 14, 'D': 15, 'E': 16, 'F': 17, 'G': 18, 'H': 19, 'I': 20, 'J': 21, 'K': 22, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'Q': 28, 'R': 29, 'S': 30, 'T': 31, 'U': 32, 'V': 33, 'W': 34, 'Y': 35, 'Z': 36, '[': 37, ']': 38, '_': 39, 'a': 40, 'b': 41, 'c': 42, 'd': 43, 'e': 44, 'f': 45, 'g': 46, 'h': 47, 'i': 48, 'j': 49, 'k': 50, 'l': 51, 'm': 52, 'n': 53, 'o': 54, 'p': 55, 'q': 56, 'r': 57, 's': 58, 't': 59, 'u': 60, 'v': 61, 'w': 62, 'x': 63, 'y': 64, 'z': 65}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: ':', 10: ';', 11: '?', 12: 'A', 13: 'B', 14: 'C', 15: 'D', 16: 'E', 17: 'F', 18: 'G', 19: 'H', 20: 'I', 21: 'J', 22: 'K', 23: 'L', 24: 'M', 25: 'N', 26: 'O', 27: 'P', 28: 'Q', 29: 'R', 30: 'S', 31: 'T', 32: 'U', 33: 'V', 34: 'W', 35: 'Y', 36: 'Z', 37: '[', 38: ']', 39: '_', 40: 'a', 41: 'b', 42: 'c', 43: 'd', 44: 'e', 45: 'f', 46: 'g', 47: 'h', 48: 'i', 49: 'j', 50: 'k', 51: 'l', 52: 'm', 53: 'n', 54: 'o', 55: 'p', 56: 'q', 57: 'r', 58: 's', 59: 't', 60: 'u', 61: 'v', 62: 'w', 63: 'x', 64: 'y', 65: 'z'}\n"
     ]
    }
   ],
   "source": [
    "def get_key_by_value(dictionary, value):\n",
    "    return next(key for key, val in dictionary.items() if val == value)\n",
    "\n",
    "input_vector = []\n",
    "input_string = \"And a speak anything against me\"\n",
    "output_string = []\n",
    "dictionary_set_reversed = {value: key for key, value in dictionary_set.items()}\n",
    "for i in range(len(input_string)):\n",
    "    input_vector.append(dictionary_set[input_string[i]]/vocab_size)\n",
    "input_vector = input_vector[-input_size:]\n",
    "\n",
    "for i in range(50):\n",
    "    #print(input_vector)\n",
    "    predicted = trainer.predict(torch.tensor(input_vector).type(torch.FloatTensor))\n",
    "    predicted = predicted*vocab_size\n",
    "    predicted = round(float(predicted[0].float()))\n",
    "    predicted = max(0, predicted)\n",
    "    predicted = min(vocab_size -1, predicted)\n",
    "    output_string.append(dictionary_set_reversed[predicted])\n",
    "    input_vector = input_vector[1:]\n",
    "    input_vector.append(predicted/vocab_size)\n",
    "for i in range(len(output_string)):\n",
    "    print(output_string[i], end=\"\")\n",
    "print()\n",
    "print(output_string)\n",
    "print(dictionary_set)\n",
    "print(dictionary_set_reversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa4638-1280-4074-b1b3-1b21cefad2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
